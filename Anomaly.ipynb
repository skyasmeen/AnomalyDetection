{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcHSSAhpxwtI",
        "outputId": "e1af0b7e-d82e-45db-85a6-e86f0003b080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hSelected features: 25\n",
            "Epoch 1/20\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.6290 - val_loss: 0.2126\n",
            "Epoch 2/20\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1556 - val_loss: 0.0968\n",
            "Epoch 3/20\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1039 - val_loss: 0.0563\n",
            "Epoch 4/20\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0813 - val_loss: 0.0446\n",
            "Epoch 5/20\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0665 - val_loss: 0.0412\n",
            "Epoch 6/20\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0563 - val_loss: 0.0368\n",
            "Epoch 7/20\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0464 - val_loss: 0.0330\n",
            "Epoch 8/20\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0294 - val_loss: 0.0299\n",
            "Epoch 9/20\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0259 - val_loss: 0.0294\n",
            "Epoch 10/20\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0314 - val_loss: 0.0239\n",
            "Epoch 11/20\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0228 - val_loss: 0.0273\n",
            "Epoch 12/20\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0258 - val_loss: 0.0216\n",
            "Epoch 13/20\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0319 - val_loss: 0.0235\n",
            "Epoch 14/20\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0274 - val_loss: 0.0218\n",
            "Epoch 15/20\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0173 - val_loss: 0.0179\n",
            "Epoch 16/20\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0169 - val_loss: 0.0177\n",
            "Epoch 17/20\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0323 - val_loss: 0.0177\n",
            "Epoch 18/20\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0260 - val_loss: 0.0168\n",
            "Epoch 19/20\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0225 - val_loss: 0.0150\n",
            "Epoch 20/20\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0152 - val_loss: 0.0144\n",
            "\u001b[1m2573/2573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
            "\u001b[1m3521/3521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step\n",
            "\n",
            "===== Extra Trees =====\n",
            "Accuracy: 0.8046619798324102\n",
            "Balanced Accuracy: 0.807491069022892\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Attack       0.95      0.65      0.77     57343\n",
            "      Normal       0.73      0.96      0.83     55313\n",
            "\n",
            "    accuracy                           0.80    112656\n",
            "   macro avg       0.84      0.81      0.80    112656\n",
            "weighted avg       0.84      0.80      0.80    112656\n",
            "\n",
            "\n",
            "===== CatBoost =====\n",
            "Accuracy: 0.8315136344269279\n",
            "Balanced Accuracy: 0.8339944782671558\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Attack       0.96      0.70      0.81     57343\n",
            "      Normal       0.76      0.97      0.85     55313\n",
            "\n",
            "    accuracy                           0.83    112656\n",
            "   macro avg       0.86      0.83      0.83    112656\n",
            "weighted avg       0.86      0.83      0.83    112656\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# =========================================================\n",
        "# UNSW-NB15 Binary Anomaly Detection\n",
        "# EO + SAE + SMOTE + ExtraTrees + CatBoost\n",
        "# FAST, REALISTIC, PAPER-SAFE (SEEDED)\n",
        "# =========================================================\n",
        "\n",
        "!pip install -q catboost tensorflow imbalanced-learn\n",
        "\n",
        "# =======================\n",
        "# 0. RANDOM SEEDS\n",
        "# =======================\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "SEED = 42\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# =======================\n",
        "# 1. IMPORTS\n",
        "# =======================\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, balanced_accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# =========================================================\n",
        "# 2. LOAD DATA\n",
        "# =========================================================\n",
        "\n",
        "train_df = pd.read_csv(\"UNSW_NB15_training-set.csv\")\n",
        "test_df  = pd.read_csv(\"UNSW_NB15_testing-set.csv\")\n",
        "\n",
        "# Handle missing values\n",
        "train_df.fillna(0, inplace=True)\n",
        "test_df.fillna(0, inplace=True)\n",
        "\n",
        "# Binary labels\n",
        "train_df['label'] = train_df['label'].map({0: 'Normal', 1: 'Attack'})\n",
        "test_df['label']  = test_df['label'].map({0: 'Normal', 1: 'Attack'})\n",
        "\n",
        "# Drop unused columns\n",
        "train_df.drop(columns=['id', 'attack_cat'], inplace=True)\n",
        "test_df.drop(columns=['id', 'attack_cat'], inplace=True)\n",
        "\n",
        "# =========================================================\n",
        "# 3. ENCODING\n",
        "# =========================================================\n",
        "\n",
        "cat_cols = ['proto', 'service', 'state']\n",
        "\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    all_vals = pd.concat([train_df[col], test_df[col]]).astype(str)\n",
        "    le.fit(all_vals)\n",
        "    train_df[col] = le.transform(train_df[col].astype(str))\n",
        "    test_df[col]  = le.transform(test_df[col].astype(str))\n",
        "\n",
        "target_le = LabelEncoder()\n",
        "train_df['label'] = target_le.fit_transform(train_df['label'])\n",
        "test_df['label']  = target_le.transform(test_df['label'])\n",
        "\n",
        "X_train = train_df.drop('label', axis=1).values\n",
        "y_train = train_df['label'].values\n",
        "X_test  = test_df.drop('label', axis=1).values\n",
        "y_test  = test_df['label'].values\n",
        "\n",
        "# =========================================================\n",
        "# 4. SCALING\n",
        "# =========================================================\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test  = scaler.transform(X_test)\n",
        "\n",
        "# =========================================================\n",
        "# 5. EQUILIBRIUM OPTIMIZER (FEATURE SELECTION)\n",
        "# =========================================================\n",
        "\n",
        "def fitness(sol, X, y):\n",
        "    if sol.sum() == 0:\n",
        "        return 1\n",
        "    Xs = X[:, sol == 1]\n",
        "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
        "    scores = []\n",
        "\n",
        "    for tr, val in skf.split(Xs, y):\n",
        "        clf = ExtraTreesClassifier(\n",
        "            n_estimators=50,\n",
        "            class_weight='balanced',\n",
        "            n_jobs=-1,\n",
        "            random_state=SEED\n",
        "        )\n",
        "        clf.fit(Xs[tr], y[tr])\n",
        "        pred = clf.predict(Xs[val])\n",
        "        scores.append(balanced_accuracy_score(y[val], pred))\n",
        "\n",
        "    return 1 - np.mean(scores)\n",
        "\n",
        "def EO(X, y, pop=10, iters=10):\n",
        "    n_feat = X.shape[1]\n",
        "    P = np.random.randint(0, 2, (pop, n_feat))\n",
        "    F = np.array([fitness(p, X, y) for p in P])\n",
        "\n",
        "    for _ in range(iters):\n",
        "        elite = P[np.argsort(F)[:3]]\n",
        "        eq = elite.mean(axis=0)\n",
        "\n",
        "        for i in range(pop):\n",
        "            P[i] = (np.random.rand(n_feat) < eq).astype(int)\n",
        "            F[i] = fitness(P[i], X, y)\n",
        "\n",
        "    return P[np.argmin(F)]\n",
        "\n",
        "best_features = EO(X_train, y_train)\n",
        "X_train = X_train[:, best_features == 1]\n",
        "X_test  = X_test[:, best_features == 1]\n",
        "\n",
        "print(\"Selected features:\", X_train.shape[1])\n",
        "\n",
        "# =========================================================\n",
        "# 6. STACKED AUTOENCODER\n",
        "# =========================================================\n",
        "\n",
        "inp = Input(shape=(X_train.shape[1],))\n",
        "x = Dense(64, activation='relu')(inp)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "latent = Dense(16, activation='relu')(x)\n",
        "x = Dense(32, activation='relu')(latent)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "out = Dense(X_train.shape[1])(x)\n",
        "\n",
        "autoencoder = Model(inp, out)\n",
        "encoder = Model(inp, latent)\n",
        "\n",
        "autoencoder.compile(optimizer=Adam(0.001), loss='mse')\n",
        "autoencoder.fit(\n",
        "    X_train, X_train,\n",
        "    epochs=20,\n",
        "    batch_size=256,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[EarlyStopping(patience=4, restore_best_weights=True)],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "X_train_enc = encoder.predict(X_train)\n",
        "X_test_enc  = encoder.predict(X_test)\n",
        "\n",
        "# =========================================================\n",
        "# 7. SMOTE (CLASS IMBALANCE HANDLING)\n",
        "# =========================================================\n",
        "\n",
        "X_train_enc, y_train = SMOTE(random_state=SEED).fit_resample(X_train_enc, y_train)\n",
        "\n",
        "# =========================================================\n",
        "# 8. EVALUATION FUNCTION\n",
        "# =========================================================\n",
        "\n",
        "def evaluate(name, y_true, y_pred):\n",
        "    print(f\"\\n===== {name} =====\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"Balanced Accuracy:\", balanced_accuracy_score(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred, target_names=target_le.classes_))\n",
        "\n",
        "# =========================================================\n",
        "# 9. FINAL MODELS\n",
        "# =========================================================\n",
        "\n",
        "# Extra Trees\n",
        "et = ExtraTreesClassifier(\n",
        "    n_estimators=200,\n",
        "    class_weight='balanced',\n",
        "    n_jobs=-1,\n",
        "    random_state=SEED\n",
        ")\n",
        "et.fit(X_train_enc, y_train)\n",
        "evaluate(\"Extra Trees\", y_test, et.predict(X_test_enc))\n",
        "\n",
        "# CatBoost\n",
        "cb = CatBoostClassifier(\n",
        "    iterations=300,\n",
        "    depth=7,\n",
        "    learning_rate=0.05,\n",
        "    loss_function='Logloss',\n",
        "    class_weights=[1, 1.2],\n",
        "    random_seed=SEED,\n",
        "    verbose=False\n",
        ")\n",
        "cb.fit(X_train_enc, y_train)\n",
        "evaluate(\"CatBoost\", y_test, cb.predict(X_test_enc))\n"
      ]
    }
  ]
}